# 爬虫 for 北邮教务系统

此项目为我初步学习 Python 的实践载体，将被我用于实践各种 Python 的基本及进阶技术操作

欢迎各种形式的交流学习与建议

> Mail: wenhelog@gmail.com
>
> Github:[BuWH/pythonlearning/crawler](https://github.com/BuWH/pythonlearning/tree/master/crawler)

## 基本设计功能 *todolist* 

* ~~外网访问登录~~
* ~~教务系统登录~~
* cookies 使用
* ~~爬取各类成绩~~，以 Excel 输出
* ~~绩点计算~~
* 课表

## 优化 & 进阶功能

* ~~验证码自动识别~~
  * 已使用某网站 api 实现此功能，但基于调用网络 api 效率太低，有时候甚至需要二十多秒。此方案暂时搁置，后期看能否搭建本地 OCR
* 用 log 输出替代 print
* 图形化界面
* 抢课（待定）

## 日志

> 7.23 2018

之前的 Python 学习还处于小打小闹的阶段，并没有一个项目作为学习实践的支撑。网上的爬虫教程的流程基本是先从 Requests 或者 urllib 开始 HTTP 访问，再到 BeautifulSoup、Xpath 或正则表达式爬取需要的元素，再到模拟登录。前两部我已有了大概的了解，现在开始做模拟登录。

之前所看的教程里做的是豆瓣模拟登录，我研究了几个小时后，大概知道了该怎么做。基本分为三步：

1. 使用浏览器登录目标网页，通过抓包工具获取 POST 需要的参数。若无需验证码就比较简单，一般来说有账号密码即可登录。
2. 若是需要验证码验证，就比较麻烦。根据教程，我暂时的处理方式为**将图片下载到本地，在需要验证码的时候谈出验证码图片，在命令行中完成输入**，显然这个方式有点机械且麻烦，但暂时无法避免。之后看看有没有网站或 package 能提供简单验证码的识别，尽量**自动化处理验证码**。若实在无法避免，就做一个类似客户端的登录界面，以提高体验。
3. 爬取数据…由于我对前端不是很熟悉，遇到一些动态网页还不知道怎么处理，之后再看吧。

今天主要解决了外网访问门户和教务系统的登录问题，由于外网访问门户并不是每次登录都需要验证码，我还需要判断当前页面是否需要验证码。目前已解决。

在功能实现后，为以后程序的拓展性及为更多的了解 Python 特性，将已有代码以**面向对象**的逻辑重构。效果不错。

> 7.24

今天未按计划进行。

在某网站申请了验证码识别 api 并进行了测试，由于长期使用需要收费，且识别速度太慢，暂时搁置。但已做好接口，随时可以调用。

已实现将固定页面显示的成绩爬到 txt 文件里，还没用 Excel 也还没弄翻页，稍后再研究研究。

OK，实现了以 csv 格式输出，到了这一步应该离 Excel 也不远了。之后先研究翻页爬取所有成绩及其他数据，再研究算绩点吧。

对了，**目前代码暂时没太考虑登陆失败等问题，计划的是先完成功能再完善逻辑和体验**。

> 7.26

昨天回来比较晚，没写代码。想去投 Momenta 的实习，临时做了份简历，然后发现自己太菜了，要求基本达不到。感觉我还是想做机器学习人工智能方面的东西，但是又的确不想读研，只有大三大四自己多肝一肝看能不能找到满意的实习和工作了。

决定重新搭网站，想来想去我还是要在自己的网站上持续更新日志，这样貌似对找实习也有很大帮助。

刚才把之前爬取成绩的页面改了一下，现在可以把已考的所有科目成绩爬下来，这样算绩点应该就没啥问题了。比较蛋疼的是，北邮教务系统有些值是乱的，看来还要写个函数专门处理一下这些乱码，然后再计算绩点。

> 7.28

这两天在折腾网站，没怎么写代码。

完成将科目转化为对象，并且能计算总 GPA 和必修 GPA。没用到 Excel，直接读取了 csv 文件。

主要练习了 Python 里 dict 和 list 的操作，不考虑性能的情况下，真是比 C++ 好用百倍啊。

现在看来貌似不太需要单独写入文件再读入文件，之后把文件的部分删去试试。